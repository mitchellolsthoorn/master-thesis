\chapter{\label{chap:requirements}Requirements}

% Still no good solution for code re-use

% plugin vs module vs micro-service vs middleware

%validate this with real-world complexity
%our unique requirements: ToDo into a Related Work table (red and green ticks)
%

This work sets out to create a framework for the next evolution of modularized code execution to find a balance between software re-usability and usability. This chapter specifies the requirements that were identified from the background and related work in Chapter~\ref{chap:introduction}. The key property is permission-less code execution at near-zero cost.

%There should be no difference between modules and plug-ins. Each user can also choose which functionality and therefore module they want to run on their instance of the application. This allows users to compose their own desired version of the application. The user can compose larger modules out of smaller ones or fork modules to represent their view on how it should be done. This should create a community around each module that could spark an ecosystem.

%Requirements for our envisioned runtime engine are as follows

The requirements are subdivided into three different categories namely Principles, Trustworthy Code, and Runtime Support.

\section{Principles}

These principles form the foundation of the framework and are necessary to achieve the research aim.

\subsection*{Decentralized}

For the framework to be financially sustainable it needs to be decentralized. In centralized systems, the operating costs of a network are the responsibility of the entity in control of the system. This entity would need to have continued incentive to keep operating the network. In decentralized systems, the operating cost is split across all users of the network. The number of users will scale together with the cost of the network.

Decentralization also increases the reliability of the system as there can be no central infrastructural point of failure that could bring the network down. The system should have no central servers except for bootstrapping.

\subsection*{Self-governing}

The system must be able to run by itself without supervision as there is no parent governing entity. The system should be able to handle all the tasks needed for operating the network.

To be free of external influence, no central entity or central governance can be in control of the network. The network should be owned by everybody and nobody and therefore self-governing.

Since self-governing systems are run by the system itself and its users' input, there is no single owner of the network. If the original author disappears or is mandated to hand over control to another party, the overall system is not affected and can continue to function regardless.

An example of a platform that was taken down by external pressure from lawsuits is Napster, a peer-to-peer music sharing service\cite{mccourt2003creators}. Although Napster used decentralization for file sharing it was still controlled by a central company. This allowed lawsuits to be filed against this company to take down the service.

\section{Trustworthy Code}

%https://harry.garrood.me/blog/malicious-code-in-purescript-npm-installer/
%https://lwn.net/Articles/740157/
%https://blog.cloudflare.com/cloudflare-architecture-and-how-bpf-eats-the-world/
%https://news.ycombinator.com/item?id=19947970
%https://arstechnica.com/information-technology/2018/06/backdoored-images-downloaded-5-million-times-finally-removed-from-docker-hub/

Since this work is proposing a framework that is highly dependent on re-usable code, it is important that the user running the application can trust all its parts. This trust aspect is very important for a code execution ecosystem. There are countless examples of applications being compromised by running untrusted code~\cite{purescript}\cite{docker}.

\subsection*{Open Ecosystem}
For a user to trust the application they want to run, they also need to trust the framework running it. That is why every part of the code execution ecosystem must be open for inspection. Making the source code public allows users or external parties to verify the behavior of the system. 

Next to opening up the framework for inspection, it is also of vital importance that each re-usable component used within the framework can be inspected to increase the trustworthiness of the code.

\subsection*{Crowdsourcing}
DevID is a previous work of the authors of this thesis. It evaluates the possibility of using social trust as a way to increase the trustworthiness of code by using crowdsourced peer-review~\cite{de2019devid}.

Cargo Crev is a cryptographically verifiable code review system for the cargo (Rust) package manager~\cite{cargocrev}. It lets users cryptographically sign packages when they have deemed them to be safe.

Both of these systems make use of crowdsourcing to minimize the risk of users running undesired malicious code. This is a very important property since manually inspecting all code running in an application can take a lot of time. By crowdsourcing this task to other individuals, the trustworthiness might be lower compared to reviewing it yourself. However, because the code review is crowdsourced to many different individuals, the eventual trustworthiness of the code will be higher.

\subsection*{Dependencies}
The current dependency trend is risky, developers trust more code with less justification for doing so. Since the recent explosion of code re-use systems, applications started shifting to using more and more existing libraries in the form of dependencies. This rapid shift, however, has caused developers to take along their perspective on code trustworthiness of classical dependencies like OS system libraries. The trust-ability of these new libraries is not as obvious as most developers believe.

H2020 FASTEN is a project that strives to minimize the risk associated with using dependencies~\cite{fasten}. Its solution to this problem is performing static analysis of the code and creating a dependency graph. With this dependency graph, changes to the dependency can be detected. This allows inspection of the code that would be affected by this change.

When using dependencies without inspection, applications risk running code that contains bugs or has security exploits. Next to this, when the author of the dependency decides to change the purpose of their dependency or remove it entirely, the depending application becomes broken and useless. A study done by Xavier et al has looked into the impact of breaking changes in dependencies~\cite{xavier2017historical}. They determined it poses a great risk to an application, since the frequency of breaking changes and the impact are high in many cases.

Although Semantic Versioning is a system designed to indicate to developers when breaking changes have been made to the dependency, the system is not being used properly according to recent studies~\cite{raemaekers2014semantic}~\cite{raemaekers2017semantic}. Raemaekers et al found that backward-incompatible changes are widespread in software libraries.

\subsection*{Trust Function}
Trustworthy code is a cornerstone of software development. However, how is trust defined? Trust is a social notion. One person might need more or less information to trust a particular piece of code than another person. This is highly dependent on the social constructs of the user. Therefore, trust shouldn't be a fixed concept. Each user should be able to define a trust function that is used to determine if a dependency should be used or not.

\section{Runtime Support}

A key bottleneck for re-usability and usability is the lack of runtime support within the execution environment.

\subsection*{Integrated Autonomous Dissemination}

Centralized systems store all code libraries in one or multiple central locations. These locations require a lot of technical infrastructure which is not free. Besides this, they also have several downsides. One downside is that these locations are susceptible to the influence of governments. They can be blocked or shut down when the government feels like the platform is not complying with its laws. Decentralized systems do not have this disadvantage. Another disadvantage of centralized library storage is that any library made by revoked at any time.

A system that has integrated autonomous dissemination of code libraries through decentralized methods, can not be controlled from outside the system. It also allows everything to be done from inside the framework making it easier to use.

\subsection*{Dynamic Loading}

For the code execution framework to be easy to use, the user should not have to restart the application or load applications into the framework. This should be done automatically on-demand by the framework. Dynamic loading would also make sure that only the application that should be running are loaded into the system so that unused applications will not waste computer resources.

%https://pyrasite.readthedocs.io/en/latest/GUI.html
%https://en.wikipedia.org/wiki/Kpatch

\subsection*{Seamless Upgrading}

Updating of dependencies is very important. Outdated dependencies that contain security exploits can seriously harm the system it is running on. So when a new version of a dependency is available on the network, it should automatically be distributed to all nodes that run applications depending on that dependency. There should be no user action required for updating to happen. Once the dependency is available on the host computer, it should do an in-place replacement of the dependency in the framework.

A similar system has been proposed by Rellermeyer et al for Java OSGi modules~\cite{rellermeyer2008consistently}. In this paper, they devise a mechanism to extend the default functionality of OSGi modules to make it possible to upgrade them when used in a distributed method.

\subsection*{Module Interconnect}

%JVM, Nodejs, CPAN perl modules and other real-world framework and the connection between modules determine the Maximum Complexity of Applications (MCA) which a single company, an global consortium, or open source community can create.

For applications to be built up out of modules, there has to be a way for modules to find each other and to communicate with each other. The way this connection is constructed is very important since the code execution architecture defines the maximum complexity of the code that can be produced. The type of module and the connection between them determine the Maximum Complexity of Applications (MCA) which a single company, a global consortium, or open-source community can create. We devised the first architecture to take the MCA as the cardinal design optimisation. 

%Science what defines MCA? What constrains/boosts MCA? The interconnection fabric is the key determinant of the MCA. How data flows between modules, how the future-proofing is arranged, how any piece of code can interconnect with any other code, and how can we devise the universal module interconnector?

To optimize the MCA some properties of the interconnection fabric have to hold:
\begin{itemize}
	\item Strong encapsulation: hide implementation details inside components, leading to a low coupling between different parts. Teams can work in isolation on decoupled parts of the system.
	\item Well-defined interfaces: you can’t hide everything (or else your system won’t do anything meaningful), so well-defined and stable APIs between components is a must. A component can be replaced by any implementation that conforms to the interface specification. Rest is not ideal for this, native code is better Interfaces can't be fixed since application could be anything
	\item Explicit dependencies: having a modular system means distinct components must work together. You’d better have a good way of expressing (and verifying) their relationships.
\end{itemize}

Currently, there are some attempts at creating a universal module. One of these attempts is UMD. Universal Module Definition (UMD) strives to create a module that can run on all platforms, e.g. browser, nodeJS, that run JavaScript. UMD, however, doesn't have to deal with a lot of complexities since the interface on all platforms is almost identical and JavaScript has a common pattern for interconnection modules. Another platform that is trying to create a universal module is Java's OSGi. This platform allows modules conforming to the standard to be used interchangeably with other modules. 

%universal modules
%https://github.com/umdjs/umd
%https://www.semanticscholar.org/paper/Power-Management-for-Portable-Devices-Pouwelse/180e5b6ac7f4c8c5028985526c0249a3e16fbc75/figure/53
%http://home.wangjianshuo.com/mvm/001157.htm
%Java OSGi or Java 9 native modules or JavaScript got a module system as of ES2015

\subsection*{Module Definition}

There should be no difference between modules and plug-ins. Each user can also choose which functionality and therefore module they want to run on their instance of the application. This allows users to compose their own desired version of the application. The user can compose larger modules out of smaller ones or fork modules to represent their view on how it should be done. This should create a community around each module that could spark an ecosystem.

% protocols should be lightweight.


